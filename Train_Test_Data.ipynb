{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import QMessageBox\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "\n",
    "class train_test_data():\n",
    "    TRAIN_DATADIR = \"Images\\Train\"\n",
    "    Validation_DATADIR = \"Images\\Validation\"\n",
    "    CATEGORIES = [\"angry\",\"disgust\",\"fear\" ,\"happy\",\"sad\",\"surprise\"]\n",
    "    IMG_SIZE = 48\n",
    "    training_data = []\n",
    "    Validation_data=[]\n",
    "    X = [] #for Input features of Train Data\n",
    "    y = [] #for Labels of Train Data\n",
    "    VAl_X = [] #for Input features of Validation_data\n",
    "    VAl_y = [] #for Labels of Validation_data\n",
    "    \n",
    "#-----------Split features and labels from training and validation dataset also ------------------------\n",
    "    def split_train_text_data(self):\n",
    "        #----------Store traning and validating dataset features and labels into different variables--------\n",
    "        for features,label in self.training_data:\n",
    "            self.X.append(features)\n",
    "            self.y.append(label)\n",
    "\n",
    "        for features,label in self.Validation_data:\n",
    "            self.VAl_X.append(features)\n",
    "            self.VAl_y.append(label)\n",
    "\n",
    "        # reshape data to have a single channel\n",
    "        self.y=np.array(self.y)\n",
    "        self.VAl_y=np.array(self.VAl_y)\n",
    "\n",
    " #----------------Shape the dataset according to your model requirment(input)--------------\n",
    "        self.X=np.array(self.X)\n",
    "        self.VAl_X = np.array(self.VAl_X)\n",
    "        self.X = self.X.reshape((self.X.shape[0], self.X.shape[1], self.X.shape[2], 1))\n",
    "        self.VAl_X = self.VAl_X.reshape((self.VAl_X.shape[0], self.VAl_X.shape[1], self.VAl_X.shape[2], 1))\n",
    "        self.X = self.X.astype('float32') / 255.0\n",
    "        self.VAl_X = self.VAl_X.astype('float32') / 255.0\n",
    "        \n",
    "\n",
    "\n",
    "#------store Encoded Data Set for Futhare use if required Shape the dataset according to your model requirment(input)--\n",
    "\n",
    "    def save_DataSet(self):\n",
    "        pickle_out = open(\"SavedDataSet\\X.pickle\",\"wb\")\n",
    "        pickle.dump(self.X, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        pickle_out = open(\"SavedDataSet\\y.pickle\",\"wb\")\n",
    "        pickle.dump(self.y, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        pickle_out = open(\"SavedDataSet\\VAl_X.pickle\",\"wb\")\n",
    "        pickle.dump(self.VAl_X, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        pickle_out = open(\"SavedDataSet\\VAl_y.pickle\",\"wb\")\n",
    "        pickle.dump(self.VAl_y, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        \n",
    "        \n",
    "#---------Create the training Data According to our dataset inputs and labels----------------------\n",
    "    def create_training_data(self):  #Function That Create Training Data Form File\n",
    "        for category in self.CATEGORIES:  # do for all Face Categories\n",
    "            path = os.path.join(self.TRAIN_DATADIR,category)  #create path to Faces\n",
    "            class_num = self.CATEGORIES.index(category)  #get the classification(0 to 5). 0=Angry 1=Disgust....\n",
    "\n",
    "            for img in tqdm(os.listdir(path)):  # iterate over each image per Face Categories\n",
    "                try:\n",
    "                    Original_img = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                   \n",
    "                    laplacian =cv2.Laplacian(Original_img,cv2.CV_64F)\n",
    "                    img_array=Original_img-laplacian \n",
    "\n",
    "                    self.training_data.append([img_array, class_num])  # add this to our training_data\n",
    "                except Exception as e:  # in the interest in keeping the output clean...\n",
    "                    pass\n",
    "\n",
    "#---------Create the validation Data According to our dataset inputs and labels----------------------\n",
    "    def create_Validation_data(self):\n",
    "        for category in self.CATEGORIES:  # do for all Face Categories\n",
    "            path = os.path.join(self.Validation_DATADIR,category)  #create path to Faces\n",
    "            class_num = self.CATEGORIES.index(category)  #get the classification(0 to 5).0=Angry 1=Disgust ....\n",
    "\n",
    "            for img in tqdm(os.listdir(path)):  # iterate over each image per Face Categories\n",
    "                try:\n",
    "                    Original_img = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                    laplacian =cv2.Laplacian(Original_img,cv2.CV_64F)\n",
    "                    img_array=Original_img-laplacian\n",
    "\n",
    "                    self.Validation_data.append([img_array, class_num])  # add this to our Validation_data\n",
    "                except Exception as e:  # in the interest in keeping the output clean...\n",
    "                    pass\n",
    "                \n",
    "#def plotImages(images_arr):\n",
    " #   fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "  #  axes = axes.flatten()\n",
    "   # for img, ax in zip( images_arr, axes):\n",
    "    #    ax.imshow(img)\n",
    "     #   ax.axis('off')\n",
    "        \n",
    "   # plt.tight_layout()\n",
    "   # plt.show()\n",
    "#aug = [training_data[0][0] for i in range(10)]\n",
    "#plotImages(aug)\n",
    "\n",
    "    def update_Train_Test_Data(self):\n",
    "       \n",
    "        self.create_training_data()\n",
    "        print(\"creation of training data Done.....\")\n",
    "        print('lenght of training data : %d' %len(self.training_data))    \n",
    "        print(\" \")\n",
    "\n",
    "        self.create_Validation_data()\n",
    "        print(\"creation of Validation data Done.....\")\n",
    "        print('lenght of validation data : %d' %len(self.Validation_data))\n",
    "\n",
    "        print(\" \")\n",
    "        print(\"Spliting training and validation dataset into features and labels...\")\n",
    "        self.split_train_text_data()\n",
    "        print(\"training and validation dataset splited successfully..\")\n",
    "\n",
    "        print(\"saving data set to local file...\")\n",
    "        self.save_DataSet()\n",
    "        print(\"Dataset saved succesfully..\")\n",
    "        \n",
    "        msgBox = QMessageBox()\n",
    "        msgBox.setIcon(QMessageBox.Information)\n",
    "        msgBox.setText(\"Update Dataset succesfully\")\n",
    "        msgBox.setWindowTitle(\"Update Dataset\")\n",
    "        msgBox.setStandardButtons(QMessageBox.Ok)\n",
    "        \n",
    "        returnValue = msgBox.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
