{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test images/fear.jpg\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001815A91FEE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Predicted: class=2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from keras.models import load_model\n",
    "from PyQt5.QtWidgets import QMessageBox\n",
    "import numpy as np\n",
    "from numpy import argmax ,asarray\n",
    "import pickle\n",
    "import cv2 \n",
    "\n",
    "class CNN_Model():\n",
    "    X = [] #for Input features of Train Data\n",
    "    y = [] #for Labels of Train Data\n",
    "    VAl_X = [] #for Input features of Validation_data\n",
    "    VAl_y = [] #for Labels of Validation_data\n",
    "    train_datagen = ImageDataGenerator(rotation_range=15,shear_range=0.15,zoom_range=0.15,horizontal_flip=True,)\n",
    "\n",
    "    \n",
    "    def load_Data(self):\n",
    "\n",
    "        pickle_in = open(\"SavedDataSet\\X.pickle\",\"rb\")\n",
    "        self.X = pickle.load(pickle_in)\n",
    "\n",
    "        pickle_in = open(\"SavedDataSet\\y.pickle\",\"rb\")\n",
    "        self.y = pickle.load(pickle_in)\n",
    "\n",
    "        pickle_in = open(\"SavedDataSet\\VAl_X.pickle\",\"rb\")\n",
    "        self.VAl_X = pickle.load(pickle_in)\n",
    "\n",
    "        pickle_in = open(\"SavedDataSet\\VAl_y.pickle\",\"rb\")\n",
    "        self.VAl_y = pickle.load(pickle_in)\n",
    "               \n",
    "        self.train_datagen.fit(self.X)\n",
    "\n",
    "        \n",
    "        \n",
    "    def Create_Train_Model(self):\n",
    "        \n",
    "    #-----------model definition----------------\n",
    "    #-------------create the model attributes-------------------\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (5, 5), activation='relu',padding='same',input_shape=(48, 48, 1)))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Conv2D(64, (5, 5), activation='relu',padding='same'))    \n",
    "        model.add(BatchNormalization()) \n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), activation='relu',padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "            #-----------set model compilation attributes------------------------\n",
    "        model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "            #--------to just see  the Model detials-----------------------------\n",
    "        model.summary()\n",
    "        #-------train the model on data set---------------------------------\n",
    "        \n",
    "        history = model.fit(self.train_datagen.flow(self.X, self.y, batch_size=32),epochs=60,steps_per_epoch=1000,validation_data=(self.VAl_X,self.VAl_y),shuffle=True)\n",
    "    #-------------------Save the model on device------------------------\n",
    "        print(\"create and train model successfully.\")\n",
    "       # -------------------Save the model on device------------------------\n",
    "        print(\"Saving model....\")\n",
    "        model.save(\"U_Model.h5\")\n",
    "        print(\"model saved sucessfully.\")\n",
    "        print(\" \")\n",
    "        print(\"Evaluate model on validation data...\")\n",
    "        self.evaluate_Model(model,history)\n",
    "        print(\"done.\")\n",
    "        \n",
    "    def evaluate_Model(self,model,history):\n",
    "    #-----------------------evaluate the model to show the accuracy and losses-----------\n",
    "      \n",
    "        _, train_acc = model.evaluate(self.X,self.y)\n",
    "        _, test_acc = model.evaluate(self.VAl_X, self.VAl_y)\n",
    "        print('Train: %.3f, Test: %.3f' % (train_acc,test_acc))\n",
    "\n",
    "        #-------------------------plot losses during training-----------------------------\n",
    "        pyplot.subplot(211)\n",
    "        pyplot.title('Loss')\n",
    "        pyplot.plot(history.history['loss'], label='train')\n",
    "        pyplot.plot(history.history['val_loss'], label='test')\n",
    "        pyplot.legend()\n",
    "        #-------------------------plot accuracy during training-----------------------------\n",
    "        pyplot.subplot(212)\n",
    "        pyplot.title('Accuracy')\n",
    "        pyplot.plot(history.history['accuracy'], label='train')\n",
    "        pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "        pyplot.legend()\n",
    "        pyplot.show()\n",
    "        \n",
    "        \n",
    " #---------------model prediction------------------------------------------------------\n",
    "\n",
    "    def Model_prediction(self,filename):\n",
    "    #--------------Load the saved model from file\n",
    "        model = load_model('U_Model.h5')\n",
    "        CATEGORIES = [\"angry\",\"disgust\",\"fear\",\"happy\",\"sad\",\"surprise\"]\n",
    "        model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "                \n",
    "        #-----------Read and reshape the Image for prediction-----------------------\n",
    "        print(filename)\n",
    "\n",
    "        Original_img = cv2.imread(filename,cv2.IMREAD_GRAYSCALE)\n",
    "        #Original_img = cv2.imread('test/Sad.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        laplacian =cv2.Laplacian(Original_img,cv2.CV_64F)\n",
    "        img=Original_img-laplacian\n",
    "\n",
    "        img = cv2.resize(img,(48,48))\n",
    "        img = img.reshape((img.shape[0], img.shape[1], 1))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        classes = model.predict(np.asarray([img]))\n",
    "        #-----------------print the predicted class for given image-------------------------------\n",
    "        print('Predicted: class=%d' % np.argmax(classes))\n",
    "        y_classes = classes.argmax(axis=1)\n",
    "        #print(CATEGORIES[int(y_classes)])\n",
    "        return CATEGORIES[int(y_classes)]\n",
    "        #----------------------------------------------------------------------------------------\n",
    "\n",
    "    def update_model(self):\n",
    "\n",
    "        print(\"Loading Data...\")\n",
    "        self.load_Data()\n",
    "        print(\"done.\")\n",
    "        print(\"Create and Fit model....\")\n",
    "        self.Create_Train_Model()\n",
    "        print(\"done..\")\n",
    "        \n",
    "        msgBox = QMessageBox()\n",
    "        msgBox.setIcon(QMessageBox.Information)\n",
    "        msgBox.setText(\"Update Model succesfully\")\n",
    "        msgBox.setWindowTitle(\"Update Model\")\n",
    "        msgBox.setStandardButtons(QMessageBox.Ok)\n",
    "        \n",
    "        returnValue = msgBox.exec()\n",
    "        \n",
    "        \n",
    "#cnn=CNN_Model()\n",
    "#cnn.Model_prediction('test images/fear.jpg')\n",
    "#cnn.update_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
